#!/bin/bash

# Determine if we're kerberos enabled and attempt to find a working
# ticket before we start using hadoop commands, otherwise this just
# causes timeouts.

if [[ -f /etc/krb5.conf ]] ; then
    PATH=$PATH:/usr/kerberos/bin; export PATH
    klist -s
    if [[ $? == 1 ]]; then
        echo "Found Kerberos config, but could not find valid TGT."
        echo "Try authenticating with kinit."
        exit 1
    fi
fi

# some defaults; try to figure out our domain and which hadoop cluster
# this host is configured for by default.
domain=$(facter domain 2>/dev/null)
cluster=$(hadoop fs -cat /CLUSTERNAME 2> /dev/null | grep ^cluster: | cut -f2 -d' ' || echo 'unknown')

# script defaults
sleep=900
notify_to=root

show_help() {
    cat <<EOF

    Usage: ${0##*/} [-ks] [-?|-h] [-d domainname] [-c clustername] ...

      Used for generating URL for curl
        -c    clustername (default: $cluster)
        -d    domainname  (default: $domain)

      Job operations
        -k    kill any found jobs that are in "Error launching tasks"

      Security

        -s    check for kerberos key first

      Other
        -t    sleep period between checks: default $sleep
        -n    send email notification    : default $notify_to
        -v    verbose
        -?    help
        -h    help
EOF
}
        

OPTIND=1
while getopts "ksvc:d:n:t:" opt ; do
    case "$opt" in
        c)  cluster=$OPTARG
        ;;
        d)  domain=$OPTARG
        ;;
        k) kill_jobs=1
        ;;
        s)  # enable checking for kerberos key
            security=1
        ;;
        v) verbose=1
        ;;
        t) sleep=$OPTARG
        ;;
        '?'|h) show_help >&2
            exit 1
        ;;
        *)
        ;;
    esac
done
shift "$((OPTIND-1))" # shift off the options and optional --

klist_test() {
    klist -s
    if [[ $? -gt 0 ]] ; then
        mail -s "$0 kerberos authentication isn't working. ticket expired; k5start dead for $USER?" "$notify_to" < /dev/null > /dev/null 2>&1
        exit 1
    fi
}

#
if [[ -z $cluster ]] ; then
    echo "Could not determine the clustername for this host"
    exit 1
fi

while : ; do


    run_status=$(mktemp /tmp/mapred_find_stuck_tasks.XXXXXXX) || exit 1

    for i in jobtracker1 jobtracker2 ; do
	klist_test

        jt=`hadoop mrhaadmin -getServiceState $i 2>/dev/null`
        case $jt in
            active) active_jt=$i
                break
                ;;
            *);;
        esac
    done

    job_list=$(hadoop job -list 2>/dev/null | grep job_ | cut -f1)

    for job in $job_list ; do
        for type in map reduce ; do
            url="http://${active_jt}.${cluster}.hdp.${domain}:50030/jobtasks.jsp?jobid=$job&type=$type&pagenum=1&state=running"

            if [[ $verbose ]] ; then echo Attempting to query $job task type $type at $url >> "$run_status"; fi
            curl -s "$url" | grep -q "Error launching task" 

            # save off the pipe status so we can re-use it a few times
            status=(${PIPESTATUS[@]})
            curl_status=${status[0]}
            grep_status=${status[1]}

            if [[ "${curl_status}" -gt 0 ]] ; then
                echo "Curl failed for status of $job type $type; exit ${PIPESTATUS[0]}" >> "$run_status"
                continue
            fi

            if [[ "${grep_status}" -eq 0 ]] ; then
                echo "$job: errors launching tasks" >> "$run_status"
                if [[ -n "${kill_jobs}" ]] ; then
                    echo "Attempting to kill $job" >> "$run_status"
                    klist_test
                    hadoop job -kill $job >> "$run_status" 2>&1
                fi
            fi
        done
    done    

    if grep -q "errors launching tasks" "$run_status" ; then
        mail -s "$0 killed tasks" "$notify_to" < "$run_status" > /dev/null 2>&1
    fi

    find /tmp -maxdepth 1 -name "mapred_find_stuck_tasks.*" -type f -mtime +1 -print0 | xargs --no-run-if-empty -0 rm -f

    sleep $sleep
done
